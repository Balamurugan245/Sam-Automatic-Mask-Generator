# ğŸ§  Segment Anything Model (SAM) â€” ViT-B / ViT-L / ViT-H Segmentation

This repository demonstrates **automatic image segmentation** using **Meta AI's Segment Anything Model (SAM)** â€” tested across three variants:  
**ViT-B (Base)**, **ViT-L (Large)**, and **ViT-H (Huge)**.

Each version processes uploaded images, generates high-quality binary masks, saves them as `.npy` files, and visualizes overlay masks for easy inspection.

---

## ğŸš€ Features

- ğŸ”¹ Supports **SAM-B**, **SAM-L**, and **SAM-H** model checkpoints  
- ğŸ¨ Saves both `.npy` mask arrays and colored overlay visualizations  
- âš™ï¸ GPU memory tracking (`Before | After | Peak`)  
- â±ï¸ Processing time measurement per image  
- ğŸ§© Edge-enhancement preprocessing for better segmentation  
- ğŸ§° Compatible with Google Colab and local environments  

---

# SAM - BASE
<p align="center">
<img src="BASE" alt="Mask viewer">
</p>

# SAM - LARGE
<p align="center">
<img src="LARGE.png" alt="User Interface">
</p>

# SAM - HUGE
<p align="center">
<img src="HUGE.png" alt="Mask viewer">
</p>

